{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar pandas si no está instalado\n",
    "\n",
    "%pip install pandas\n",
    "%pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def show_data_summary(data):\n",
    "    print(f'Size: {data.size}')\n",
    "    print(f'Columns: {len(data.columns)}')\n",
    "    print(f'Rows: {data.shape[0]}')\n",
    "    print(f'Unique clients: {len(data.client_id.unique())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data = pd.read_csv('./data.csv', delimiter='|', skipfooter=1, engine='python')\n",
    "\n",
    "show_data_summary(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove summary row\n",
    "\n",
    "data = data[(data.client_id != '(238615 rows affected)')]\n",
    "\n",
    "show_data_summary(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "\n",
    "data = data.drop_duplicates(subset=['Month', 'client_id'])\n",
    "\n",
    "show_data_summary(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clients with 9 months data\n",
    "\n",
    "nine_mouths = data.groupby('client_id')['Month'].count().reset_index()\n",
    "clients_with_9_months = data.merge(\n",
    "    nine_mouths[nine_mouths.Month == 9][['client_id']],\n",
    "    how='inner',\n",
    "    on='client_id',\n",
    ")\n",
    "\n",
    "show_data_summary(clients_with_9_months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Windows\n",
    "\n",
    "- Training window: 6 month (from 2018-11-01 to 2019-01-01)\n",
    "- Lead window: 1 month (2019-02-01)\n",
    "- Prediction window: last 2 month (2019-03-01 and 2019-04-01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last training month clients without cobranding\n",
    "\n",
    "last_training_month = '2019-01-01'\n",
    "last_training_month_data = clients_with_9_months[clients_with_9_months.Month == last_training_month]\n",
    "\n",
    "clients_without_cobranding = clients_with_9_months.merge(\n",
    "    last_training_month_data[last_training_month_data.CreditCard_CoBranding == 'No'][['client_id']],\n",
    "    how='inner',\n",
    "    on='client_id',\n",
    ")\n",
    "\n",
    "show_data_summary(clients_without_cobranding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last training month clients without package active\n",
    "\n",
    "last_training_month_data = clients_without_cobranding[\n",
    "    clients_without_cobranding.Month == last_training_month]\n",
    "\n",
    "clients_without_cobranding_without_package = clients_without_cobranding.merge(\n",
    "    last_training_month_data[last_training_month_data.Package_Active == 'No'][['client_id']],\n",
    "    how='inner',\n",
    "    on='client_id',\n",
    ")\n",
    "\n",
    "show_data_summary(clients_without_cobranding_without_package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity features\n",
    "\n",
    "identity_features_columns = [\n",
    "    'client_id', 'Month', 'First_product_dt', 'Last_product_dt',\n",
    "    'CreditCard_Premium', 'CreditCard_CoBranding', 'CreditCard_Active',\n",
    "    'Loan_Active', 'Mortgage_Active', 'SavingAccount_Active_ARG_Salary',\n",
    "    'SavingAccount_Active_ARG', 'SavingAccount_Active_DOLLAR',\n",
    "    'DebitCard_Active', 'Investment_Active',\n",
    "    'Insurance_Life', 'Insurance_Home', 'Insurance_Accidents',\n",
    "    'Insurance_Mobile', 'Insurance_ATM', 'Insurance_Unemployment', 'Sex',\n",
    "    'Client_Age_grp', 'Mobile', 'Email',  'Region', 'CreditCard_Product'\n",
    "]\n",
    "identity_features = clients_without_cobranding_without_package[\n",
    "    clients_without_cobranding_without_package.Month == last_training_month\n",
    "][identity_features_columns]\n",
    "\n",
    "show_data_summary(identity_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nulls\n",
    "# identity_features.columns[identity_features.isnull().any()].tolist() -> [Region, CreditCard_Product]\n",
    "\n",
    "# Remove nulls of Region\n",
    "region_from_future = data[data.Month == '2019-03-01'].groupby(['Region', 'client_id']).size().reset_index()\n",
    "identity_features.drop('Region', axis=1, inplace=True)\n",
    "identity_features = identity_features.merge(region_from_future[['Region', 'client_id']], on='client_id', how='left')\n",
    "identity_features['Region'] = identity_features['Region'].fillna('Missing')\n",
    "\n",
    "# Remove nulls of CreditCard_Product\n",
    "credit_card_product_from_future = data[data.Month == '2019-03-01'].groupby(['CreditCard_Product', 'client_id']).size().reset_index()\n",
    "identity_features.drop('CreditCard_Product', axis=1, inplace=True)\n",
    "identity_features = identity_features.merge(credit_card_product_from_future[['CreditCard_Product', 'client_id']], on='client_id', how='left')\n",
    "identity_features['CreditCard_Product'] = identity_features['CreditCard_Product'].fillna('Missing')\n",
    "identity_features['CreditCard_Product'] = np.where(identity_features.CreditCard_Active == 'No', 'No', identity_features.CreditCard_Product)\n",
    "\n",
    "# Add values to nulls of SavingAccount_Balance_Average\n",
    "clients_without_cobranding_without_package['SavingAccount_Balance_Average'] = np.where(\n",
    "    clients_without_cobranding_without_package.SavingAccount_Balance_Average.isnull(),\n",
    "    (clients_without_cobranding_without_package.SavingAccount_Balance_FirstDate + clients_without_cobranding_without_package.SavingAccount_Balance_LastDate) / 2,\n",
    "    clients_without_cobranding_without_package.SavingAccount_Balance_Average\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms features\n",
    "\n",
    "# Age group to ordinal\n",
    "age_group_ordinals = {\n",
    "    'Menor a 18 años': 1800,\n",
    "    'Entre 18 y 29 años': 1829,\n",
    "    'Entre 30 y 39 años': 3039,\n",
    "    'Entre 40 y 49 años': 4049,\n",
    "    'Entre 50 y 59 años': 5059,\n",
    "    'Entre 60 y 64 años': 6064,\n",
    "    'Entre 65 y 69 años': 6569,\n",
    "    'Mayor a 70 años': 7000,\n",
    "}\n",
    "identity_features['Client_Age_grp_ordinal'] = identity_features['Client_Age_grp'].map(age_group_ordinals)\n",
    "\n",
    "# Sum Insurances\n",
    "insurance_fields = [\n",
    "    'Insurance_Life',\n",
    "    'Insurance_Home',\n",
    "    'Insurance_Accidents',\n",
    "    'Insurance_Mobile',\n",
    "    'Insurance_ATM',\n",
    "    'Insurance_Unemployment',\n",
    "]\n",
    "identity_features['Active_Insurances'] = identity_features[insurance_fields].apply(lambda row: sum(np.where(row == 'Yes', 1, 0)), axis=1)\n",
    "identity_features['Active_Insurance'] = np.where(identity_features.Active_Insurances > 0, 'Ÿes', 'No')\n",
    "\n",
    "# Sum Products\n",
    "products_fields = [\n",
    "    'Loan_Active',\n",
    "    'Mortgage_Active',\n",
    "    'CreditCard_Active',\n",
    "    'SavingAccount_Active_ARG',\n",
    "    'SavingAccount_Active_DOLLAR',\n",
    "    'DebitCard_Active',\n",
    "    'Active_Insurance',\n",
    "]\n",
    "identity_features['Active_Products'] = identity_features[products_fields].apply(lambda row: sum(np.where(row == 'Yes', 1, 0)), axis=1)\n",
    "\n",
    "show_data_summary(identity_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Operations\n",
    "operation_fields = [column for column in clients_without_cobranding_without_package.columns if 'Operations' in column]\n",
    "clients_without_cobranding_without_package['Operations'] = clients_without_cobranding_without_package[operation_fields].sum(axis=1).astype(int)\n",
    "operation_ratios = clients_without_cobranding_without_package[operation_fields].div(clients_without_cobranding_without_package['Operations'], axis=0)\n",
    "operation_ratios = operation_ratios.multiply(100).fillna(0).astype(int)\n",
    "\n",
    "for operation_field in operation_fields:\n",
    "    clients_without_cobranding_without_package[f'Operations_{operation_field}_vs_total'] = operation_ratios[operation_field]\n",
    "\n",
    "show_data_summary(clients_without_cobranding_without_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Transactions\n",
    "transaction_fields = [column for column in clients_without_cobranding_without_package.columns if 'Transactions' in column and 'SavingAccount' in column]\n",
    "clients_without_cobranding_without_package['Transactions'] = clients_without_cobranding_without_package[transaction_fields].sum(axis=1).astype(int)\n",
    "transaction_ratios = clients_without_cobranding_without_package[transaction_fields].div(clients_without_cobranding_without_package['Transactions'], axis=0)\n",
    "transaction_ratios = transaction_ratios.multiply(100).fillna(0).astype(int)\n",
    "\n",
    "for transaction_field in transaction_fields:\n",
    "    clients_without_cobranding_without_package[f'Transactions_{transaction_field}_vs_total'] = transaction_ratios[transaction_field]\n",
    "\n",
    "show_data_summary(clients_without_cobranding_without_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum Payments\n",
    "payment_fields = [column for column in clients_without_cobranding_without_package.columns if 'Payment' in column]\n",
    "clients_without_cobranding_without_package['Payments'] = clients_without_cobranding_without_package[payment_fields].sum(axis=1).astype(int)\n",
    "payment_ratios = clients_without_cobranding_without_package[payment_fields].div(clients_without_cobranding_without_package['Payments'], axis=0)\n",
    "payment_ratios = payment_ratios.multiply(100).fillna(0).astype(int)\n",
    "\n",
    "for payment_field in payment_fields:\n",
    "    clients_without_cobranding_without_package[f'Payments_{payment_field}_vs_total'] = payment_ratios[payment_field]\n",
    "\n",
    "show_data_summary(clients_without_cobranding_without_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate features\n",
    "\n",
    "# Months between products\n",
    "identity_features['First_product_dt'] = pd.to_datetime(identity_features['First_product_dt'])\n",
    "identity_features['Last_product_dt'] = pd.to_datetime(identity_features['Last_product_dt'])\n",
    "identity_features['Month'] = pd.to_datetime(identity_features['Month'])\n",
    "identity_features['Last_first_product_Months'] = ((identity_features['Last_product_dt'] - identity_features['First_product_dt']).dt.days) / 30\n",
    "identity_features['Month_first_product_Months'] = ((identity_features['Month'] - identity_features['First_product_dt']).dt.days) / 30\n",
    "identity_features['Month_last_product_Months'] = ((identity_features['Month'] - identity_features['Last_product_dt']).dt.days) / 30\n",
    "\n",
    "# Card debit vs credit\n",
    "clients_without_cobranding_without_package['Card_Debit_vs_credit'] = np.where(\n",
    "    clients_without_cobranding_without_package['SavingAccount_DebitCard_Spend_Amount'] == 0,\n",
    "    clients_without_cobranding_without_package['CreditCard_Total_Spending'],\n",
    "    (clients_without_cobranding_without_package['CreditCard_Total_Spending'] / clients_without_cobranding_without_package['SavingAccount_DebitCard_Spend_Amount'])\n",
    ")\n",
    "\n",
    "# SavingAccount debit vs credit\n",
    "clients_without_cobranding_without_package['SavingAccount_Debit_vs_credit'] = np.where(\n",
    "    clients_without_cobranding_without_package['SavingAccount_Debits_Amounts'] == 0,\n",
    "    clients_without_cobranding_without_package['SavingAccount_Credits_Amounts'],\n",
    "    (clients_without_cobranding_without_package['SavingAccount_Credits_Amounts'] / clients_without_cobranding_without_package['SavingAccount_Debits_Amounts'])\n",
    ")\n",
    "\n",
    "# Parse and add data for money fields\n",
    "# - Add value in CER - Coeficiente de Estabilización de Referencia (Argentina only)\n",
    "# - Add min, max, mean, median, etc stats values\n",
    "# - Remove outliers (from min to 3-sigma)\n",
    "CER_VALUES = {\n",
    "    '2018-08-01': 9.9316,\n",
    "    '2018-09-01': 10.2663,\n",
    "    '2018-10-01': 10.6234,\n",
    "    '2018-11-01': 11.1948,\n",
    "    '2018-12-01': 11.8454,\n",
    "    '2019-01-01': 12.3512,\n",
    "    '2019-02-01': 12.7058,\n",
    "    '2019-03-01': 13.0390,\n",
    "    '2019-04-01': 13.5000,\n",
    "}\n",
    "def calculate_with_cer(row, field):\n",
    "    month = row['Month']\n",
    "    cer_value = CER_VALUES.get(month)\n",
    "    return row[field] / cer_value\n",
    "\n",
    "def process_money_field(data, field, min=0, sigmas=3):\n",
    "    new_data = data.copy()\n",
    "\n",
    "    # Remove data from min\n",
    "    new_data[field] = np.where(new_data[field] < min, min, new_data[field])\n",
    "\n",
    "    # Remove outliers N sigmas\n",
    "    sigma = sigmas * new_data[new_data[field] >= min][field].std()\n",
    "    new_data[field] = np.where(new_data[field] > sigma, sigma, new_data[field])\n",
    "\n",
    "    # Add CER (Coeficiente de Estabilización de Referencia) value\n",
    "    field_cer = f'{field}_CER'\n",
    "    new_data[field_cer] = new_data.apply(calculate_with_cer, args=(field,), axis=1)\n",
    "\n",
    "    # Add stats columns\n",
    "    aggregations = new_data.groupby(['client_id'])[[field, field_cer]].agg([\n",
    "        np.sum, np.amax, np.min, np.mean, np.median, np.count_nonzero, np.var\n",
    "    ]).reset_index()\n",
    "    aggregations.columns = [f'{col[0]}_{col[1]}' if col[1] != '' else col[0] for col in aggregations.columns]\n",
    "    aggregations.reset_index()\n",
    "    new_data = new_data.merge(\n",
    "        aggregations[aggregations.columns],\n",
    "        how='inner',\n",
    "        on='client_id',\n",
    "    )\n",
    "\n",
    "    return new_data\n",
    "\n",
    "\n",
    "money_fields = [\n",
    "    'SavingAccount_Balance_FirstDate',\n",
    "    'SavingAccount_Balance_LastDate',\n",
    "    'SavingAccount_Balance_Average',\n",
    "    'SavingAccount_Salary_Payment_Amount',\n",
    "    'SavingAccount_Transfer_In_Amount',\n",
    "    'SavingAccount_ATM_Extraction_Amount',\n",
    "    'SavingAccount_Service_Payment_Amount',\n",
    "    'SavingAccount_CreditCard_Payment_Amount',\n",
    "    'SavingAccount_Transfer_Out_Amount',\n",
    "    'SavingAccount_DebitCard_Spend_Amount',\n",
    "    'SavingAccount_Total_Amount',\n",
    "    'SavingAccount_Credits_Amounts',\n",
    "    'SavingAccount_Debits_Amounts',\n",
    "    'CreditCard_Balance_ARG',\n",
    "    'CreditCard_Total_Limit',\n",
    "    'CreditCard_Total_Spending',\n",
    "]\n",
    "clients_with_aggregations = clients_without_cobranding_without_package.copy()\n",
    "for money_field in money_fields:\n",
    "    clients_with_aggregations = process_money_field(clients_with_aggregations, money_field, min=0 if money_field != 'SavingAccount_Balance_Average' else 150)\n",
    "clients_with_aggregations = clients_with_aggregations.groupby(['client_id']).first().reset_index()\n",
    "\n",
    "show_data_summary(identity_features)\n",
    "show_data_summary(clients_without_cobranding_without_package)\n",
    "show_data_summary(clients_with_aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print operations vs columns\n",
    "[print(col) for col in clients_with_aggregations.columns if 'Operations' in col and 'vs' in col]\n",
    "\n",
    "# Print transactions vs columns\n",
    "[print(col) for col in clients_with_aggregations.columns if 'Transactions' in col and 'vs' in col]\n",
    "\n",
    "# Print payments vs columns\n",
    "[print(col) for col in clients_with_aggregations.columns if 'Payments' in col and 'vs' in col]\n",
    "\n",
    "# Print ordinal columns\n",
    "[print(col) for col in clients_with_aggregations.columns if 'ordinal' in col]\n",
    "\n",
    "# Print Active_Insurance columns\n",
    "[print(col) for col in clients_with_aggregations.columns if 'Active_Insurance' in col]\n",
    "\n",
    "# Print money columns\n",
    "[print(col) for col in clients_with_aggregations.columns if 'CreditCard_Balance_ARG' in col and 'CER' not in col]\n",
    "[print(col) for col in clients_with_aggregations.columns if 'CreditCard_Balance_ARG' in col and 'CER' in col]\n",
    "\n",
    "show_data_summary(clients_with_aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_1 = data[(data.Month.isin(['2019-04-01', '2019-03-01']) & (data.Target == 1))][['client_id']].drop_duplicates()\n",
    "target_1['TGT'] = 1\n",
    "print('target_1')\n",
    "show_data_summary(target_1)\n",
    "print('')\n",
    "\n",
    "last_training_month_data = clients_without_cobranding_without_package[clients_without_cobranding_without_package.Month == last_training_month]\n",
    "target = last_training_month_data.merge(target_1, how='left', on='client_id').fillna(0).drop('Target', axis=1)\n",
    "print('target')\n",
    "show_data_summary(target)\n",
    "print('')\n",
    "print('identity_features')\n",
    "show_data_summary(identity_features)\n",
    "print('')\n",
    "print('clients_with_aggregations')\n",
    "show_data_summary(clients_with_aggregations)\n",
    "print('')\n",
    "\n",
    "columns_to_delete_on_target = set()\n",
    "for identity_column in identity_features.columns:\n",
    "    if identity_column in target.columns:\n",
    "        columns_to_delete_on_target.add(identity_column)\n",
    "columns_to_delete_on_target.remove('client_id')\n",
    "target = target.drop(columns=columns_to_delete_on_target).reset_index()\n",
    "\n",
    "ABT = target.merge(identity_features, how='inner', on='client_id')\n",
    "\n",
    "columns_to_delete_on_aggregation = set()\n",
    "for abt_column in ABT.columns:\n",
    "    if abt_column in clients_with_aggregations.columns:\n",
    "        columns_to_delete_on_aggregation.add(abt_column)\n",
    "columns_to_delete_on_aggregation.remove('client_id')\n",
    "clients_with_aggregations = clients_with_aggregations.drop(columns=columns_to_delete_on_aggregation)\n",
    "\n",
    "ABT = ABT.merge(clients_with_aggregations, how='inner', on='client_id')\n",
    "\n",
    "print('ABT')\n",
    "show_data_summary(ABT)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with unique values\n",
    "\n",
    "x = pd.DataFrame(ABT.describe().T)\n",
    "delete = x[x['min'] == x['max']].reset_index()\n",
    "delete.head(200)\n",
    "\n",
    "columns_to_delete = delete['index'].tolist()\n",
    "ABT = ABT.drop(columns=columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "\n",
    "## Convert columns with dtype object to dtype string\n",
    "ABT = ABT.convert_dtypes()\n",
    "string_columns = ABT.select_dtypes('string').columns\n",
    "\n",
    "# Get correlation matrix\n",
    "corr_matrix = ABT.drop(['client_id', 'TGT'] + list(string_columns), axis=1).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)).fillna(0)\n",
    "\n",
    "# Find features with correlation greater than 0.80\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "\n",
    "# Create csv to check\n",
    "upper.to_csv('./correlation.csv', sep='|',  header=True , encoding='utf-8', index=False)\n",
    "\n",
    "# Drop features \n",
    "ABT.drop(to_drop, axis=1, inplace = True)\n",
    "\n",
    "show_data_summary(ABT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install sklearn (scikit-learn)\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization ABT\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_columns = set(ABT.select_dtypes(include=['int', 'float']).columns)\n",
    "numeric_columns.remove('client_id')\n",
    "numeric_columns.remove('TGT')\n",
    "scaler = StandardScaler()\n",
    "ABT[list(numeric_columns)] = scaler.fit_transform(ABT[list(numeric_columns)])\n",
    "\n",
    "string_columns = ABT.select_dtypes(include=['string']).columns\n",
    "ABT = pd.get_dummies(ABT, columns=string_columns)\n",
    "\n",
    "datetime_columns = ABT.select_dtypes(include='datetime').columns\n",
    "for datetime_column in datetime_columns:\n",
    "    ABT[datetime_column] = ABT[datetime_column].astype(int) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lightgbm\n",
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def get_feature_importances_and_evalute_model(Table):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(Table.drop('TGT', axis=1), Table['TGT'], test_size=0.2, random_state=42)\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'num_leaves': 20,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'min_data_in_leaf': 50,\n",
    "    }\n",
    "\n",
    "    num_round = 1000\n",
    "    lgb_model = lgb.train(params, train_data, num_round, valid_sets=[train_data, test_data], callbacks=[lgb.early_stopping(stopping_rounds=150)])\n",
    "\n",
    "    feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': lgb_model.feature_importance()})\n",
    "    feature_importances = feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    y_pred = lgb_model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(f'ROC AUC: {roc_auc}')\n",
    "\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with all columns to get the importances to simplify\n",
    "\n",
    "feature_importances = get_feature_importances_and_evalute_model(ABT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate model with best 25 features\n",
    "\n",
    "top_25_features = feature_importances.head(25)['feature'].tolist()\n",
    "ABT_top_25 = ABT[top_25_features + ['TGT']]\n",
    "get_feature_importances_and_evalute_model(ABT_top_25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning-UIi7gfOb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
